# LeNet-5 Models for Handwriting Recognition Based on Pynq-Z1

## Description
This project focuses on training and quantizing the LeNet-5 CNN deep learning model and deploying it on the PYNQ-Z1 platform utilizing its FPGA capabilities to achieve efficient hardware-accelerated inference for edge AI applications. This project involves testing and comparing  inference accuracy and execution time on the computer CPU, the processor of PYNQ-Z1, and the PYNQ-Z1 with FPGA acceleration.

## Motivation
Currently, the research and development of embedded devices have attracted growing attention. With the rapid progress of AI technology, edge AI systems are increasingly deployed in embedded systems to tackle complex tasks such as autonomous driving. These applications require both high accuracy and fast inference. However, the resource constraints of edge devices limit the performance of deep learning models. Motivated by this challenge, we aim to investigate whether deep learning models deployed on edge devices can achieve both fast and accurate inference, thereby assessing their viability for deployment on resource-constrained systems.  
LeNet-5 model is a foundational convolutional neural network (CNN), including both convolutional and fully connected layers, which is designed primarily for handwriting recognition tasks. Running the LeNet-5 model on edge devices can demonstrate the potential of deploying deep learning model on resource-limited devices. Leveraging the FPGA capabilities of the PYNQ-Z1 enables full utilization of hardware acceleration, enhancing performance and scalability for AI applications. This project will present a practical case for using FPGA to accelerate machine learning model on edge devices, integrating software and hardware to optimize embedded AI systems.
